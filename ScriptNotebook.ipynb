{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb27e6a",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "    Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd771eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from urllib.parse import quote,unquote\n",
    "import urllib.parse\n",
    "import re\n",
    "import unidecode\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28237c3",
   "metadata": {},
   "source": [
    "## Text Normalization \n",
    "    Cleaning the text from emojis and other unicode icons\n",
    "\n",
    "    link to the original thread >> https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f3a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                u\"\\U00002702-\\U000027B0\"\n",
    "                u\"\\U00002702-\\U000027B0\"\n",
    "                u\"\\U000024C2-\\U0001F251\"\n",
    "                u\"\\U0001f926-\\U0001f937\"\n",
    "                u\"\\U00010000-\\U0010ffff\"\n",
    "                u\"\\u2640-\\u2642\" \n",
    "                u\"\\u2600-\\u2B55\"\n",
    "                u\"\\u200d\"\n",
    "                u\"\\u23cf\"\n",
    "                u\"\\u23e9\"\n",
    "                u\"\\u231a\"\n",
    "                u\"\\ufe0f\"  # dingbats\n",
    "                u\"\\u3030\"\n",
    "                                            \"]+\", re.UNICODE)\n",
    "\n",
    "    # remove emojis\n",
    "    cleaned = re.sub(emoj, '', data).strip()\n",
    "    \n",
    "    # convert german umlauts before removing diacritics\n",
    "    cleaned = cleaned.replace('Ü','Ue').replace('Ä','Ae').replace('Ö', 'Oe').replace('ü', 'ue').replace('ä', 'ae').replace('ö', 'oe')\n",
    "    \n",
    "    # convert semicolon to colon to prevent CSV breaking\n",
    "    cleaned = cleaned.replace(',', '')\n",
    "    cleaned = cleaned.replace(';', ',')\n",
    "    \n",
    "    # remove diacritics\n",
    "    cleaned = unidecode.unidecode(cleaned)\n",
    "    \n",
    "    return cleaned.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fef564",
   "metadata": {},
   "source": [
    "## This is the first function that gives us the first record for the dataframe and contains the information of the target_user that we want to extract the contacts from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a05ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def employee_information(employee):\n",
    "     \n",
    "        try: \n",
    "            \n",
    "            account_name = clean_data(employee[\"title\"][\"text\"]).split(\" \") #text_normalization\n",
    "            badwords = ['Prof.', 'Dr.', 'M.A.', ',', 'LL.M.'] #text_normalization\n",
    "            \n",
    "            #text_normalization\n",
    "            \n",
    "            for word in list(account_name):\n",
    "                if word in badwords:\n",
    "                    account_name.remove(word)\n",
    "            account_name = \" \".join(account_name)\n",
    "            \n",
    "        except:\n",
    "            \n",
    "             pass\n",
    "        \n",
    "        \n",
    "        # Saerch for the position \n",
    "        try:\n",
    "            position = clean_data(employee[\"primarySubtitle\"][\"text\"])\n",
    "        except:\n",
    "            position = \"N/A\"\n",
    "\n",
    "        # Search for the location\n",
    "        try: \n",
    "            location = employee[\"secondarySubtitle\"][\"text\"]\n",
    "        except:\n",
    "            location = \"N/A\"\n",
    "\n",
    "        # Search for the profileLink\n",
    "        try:\n",
    "            profile_link = employee[\"navigationUrl\"].split(\"?\")[0]\n",
    "            profile_link = unquote(profile_link)\n",
    "        except:\n",
    "            profile_link = \"N/A\"\n",
    "\n",
    "        \n",
    "        # Search the connection_degree\n",
    "        try:\n",
    "            degree_str = employee[\"entityCustomTrackingInfo\"][\"memberDistance\"]\n",
    "            degree = int(degree_str.split(\"DISTANCE_\")[-1])\n",
    "        except:\n",
    "            degree = 0\n",
    "            \n",
    "        \n",
    "        # Search the uniqueID\n",
    "        try:\n",
    "            \n",
    "            contact_id_urn = employee['image']['attributes'][0]['detailData']['nonEntityProfilePicture']['profile']['entityUrn'].split(\":\")[-1]\n",
    "        \n",
    "        except: \n",
    "            \n",
    "            contact_id_urn = \"N/A\"\n",
    "            \n",
    "        \n",
    "        # Search the userCode\n",
    "        # Name of the LinkedIn account. \n",
    "        # e.x: https://www.linkedin.com/in/XXXX/ >> employee_information(XXXX)\n",
    "        \n",
    "        try:\n",
    "            contact_userCode = employee[\"navigationUrl\"].split(\"?\")[0].split(\"/\")[-1]\n",
    "            contact_userCode = unquote(contact_userCode)\n",
    "            \n",
    "        except:\n",
    "            contact_userCode = \"N/A\" \n",
    "            \n",
    "            \n",
    "        ## return a dictionary with all the user's information\n",
    "        return {\"userID\": contact_id_urn,\"userCode\": contact_userCode,\"Nombre\":account_name, \"Puesto\": position, \"Grado\":degree, \"Ubicacion\":location, \"Link\":profile_link}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21737811",
   "metadata": {},
   "source": [
    "## Information of the contacts of the Target\n",
    "    WE search and extract a list with the information for each of the contacts of our target_contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462cbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# li_at <- Cookie information about the active session\n",
    "# JSESSIONID <- Cookie information about the active session\n",
    "# user <- Name of the LinkedIn account. \n",
    "# e.x: https://www.linkedin.com/in/XXXX/ >> employee_information(XXXX)\n",
    "\n",
    "def contacts(user, li_at, JSESSIONID):\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/122.0.0.0', \n",
    "        'Content-type': 'application/json', \n",
    "        'Csrf-Token': JSESSIONID,\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'Connection': 'keep-alive'\n",
    "    }\n",
    "    cookies_dict = {\"li_at\": li_at, \"JSESSIONID\": JSESSIONID}\n",
    "    cod_user = quote(user)\n",
    "    \n",
    "    \n",
    "    # Get the information of the target\n",
    "    url = f\"https://www.linkedin.com/voyager/api/graphql?variables=(vanityName:{cod_user})&queryId=voyagerIdentityDashProfiles.d8946426aeb23ab919d181f179a67a4d\"\n",
    "    response = requests.get(url, headers=headers, cookies=cookies_dict)\n",
    "    r = response.json()\n",
    "    \n",
    "    \n",
    "    # Information of the target\n",
    "    user_info = r['data']['identityDashProfilesByMemberIdentity']['elements'][0]\n",
    "    id_urn = user_info['entityUrn'].split(\":\")[-1]\n",
    "    name = user_info['firstName'] + \" \" + user_info['lastName']\n",
    "    position = user_info['headline']\n",
    "    location = user_info['geoLocation']['geo']['defaultLocalizedName']\n",
    "    \n",
    "    #create a df with the information and initialize a list for the contacts\n",
    "    user_info = pd.DataFrame({\"userID\": [id_urn],\"userCode\": [cod_user],\"Nombre\": [name], \"Puesto\": [position], \"Grado\": [0], \"Ubicacion\": [location], \"Link\": [\"https://www.linkedin.com/in/\" + user]})\n",
    "    list_contacts = []\n",
    "    \n",
    "          \n",
    "    # get all the contacts iterating witha step of 3 that is the max return of the call and append the information in the list \n",
    "    \n",
    "    for i in range(0,500,3):\n",
    "        url = f\"https://www.linkedin.com/voyager/api/graphql?variables=(start:{i},origin:MEMBER_PROFILE_CANNED_SEARCH,query:(flagshipSearchIntent:SEARCH_SRP,queryParameters:List((key:connectionOf,value:List({id_urn})),(key:network,value:List(F,S,O)),(key:resultType,value:List(PEOPLE))),includeFiltersInResponse:false))&queryId=voyagerSearchDashClusters.cc5c3924cc0402d1d8838b15bc96aa0b\"\n",
    "        response = requests.get(url, headers=headers, cookies=cookies_dict)\n",
    "        r = response.json()\n",
    "        \n",
    "        # appending the information of each of the contacts\n",
    "        try:\n",
    "            list_users = r['data']['searchDashClustersByAll']['elements'][0]['items']\n",
    "            \n",
    "            for user in list_users:\n",
    "                list_contacts.append(employee_information(user[\"item\"]['entityResult']))\n",
    "                \n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "    \n",
    "    \n",
    "    #Merge the information of the target and his contacts into a unique dataframe the targets information will be the first row with a zero degree connection with himself\n",
    "    contacts = pd.DataFrame(list_contacts)\n",
    "    contacts = contacts.drop_duplicates()\n",
    "    contacts = contacts[contacts['Nombre'] != \"LinkedIn Member\"]\n",
    "    contacts = pd.concat([user_info, contacts], ignore_index=True)\n",
    "    \n",
    "    return contacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
