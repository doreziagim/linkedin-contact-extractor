{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb27e6a",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "    Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd771eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from urllib.parse import quote,unquote\n",
    "import urllib.parse\n",
    "import re\n",
    "import unidecode\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28237c3",
   "metadata": {},
   "source": [
    "## Text Normalization \n",
    "    Cleaning the text from emojis and other unicode icons\n",
    "\n",
    "    link to the original thread >> https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f3a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    #Create my target strings. All the commonly used emojis and swpecial characters i need to clean from my results.\n",
    "    emoj = re.compile(\"[\"\n",
    "                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                u\"\\U00002702-\\U000027B0\"\n",
    "                u\"\\U00002702-\\U000027B0\"\n",
    "                u\"\\U000024C2-\\U0001F251\"\n",
    "                u\"\\U0001f926-\\U0001f937\"\n",
    "                u\"\\U00010000-\\U0010ffff\"\n",
    "                u\"\\u2640-\\u2642\" \n",
    "                u\"\\u2600-\\u2B55\"\n",
    "                u\"\\u200d\"\n",
    "                u\"\\u23cf\"\n",
    "                u\"\\u23e9\"\n",
    "                u\"\\u231a\"\n",
    "                u\"\\ufe0f\"  # dingbats\n",
    "                u\"\\u3030\"\n",
    "                                            \"]+\", re.UNICODE)\n",
    "\n",
    "    # remove emojis\n",
    "    cleaned = re.sub(emoj, '', data).strip()\n",
    "    \n",
    "    # convert german umlauts before removing diacritics\n",
    "    cleaned = cleaned.replace('Ü','Ue').replace('Ä','Ae').replace('Ö', 'Oe').replace('ü', 'ue').replace('ä', 'ae').replace('ö', 'oe')\n",
    "    \n",
    "    # convert semicolon to colon to prevent CSV breaking\n",
    "    cleaned = cleaned.replace(',', '')\n",
    "    cleaned = cleaned.replace(';', ',')\n",
    "    \n",
    "    # remove diacritics\n",
    "    cleaned = unidecode.unidecode(cleaned)\n",
    "    \n",
    "    #return the final clean text stripped from any spaces\n",
    "    return cleaned.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fef564",
   "metadata": {},
   "source": [
    "## This is the first function that gives us the first record for the dataframe and contains the information of the target_user that we want to extract the contacts from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a05ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def employee_information(employee):\n",
    "     \n",
    "        #Create an error proof function that in case of no response or incorrect input will continue the loop\n",
    "        try: \n",
    "            #create a list from the name of the user splitted by spaces. e.x. 'Filippos Dorezi' >> ['Filippos','Dorezi']\n",
    "            account_name = clean_data(employee[\"title\"][\"text\"]).split(\" \") \n",
    "            \n",
    "            #Creating a list of common name titles I want to remove from the name of the user\n",
    "            badwords = ['Prof.', 'Dr.', 'M.A.', ',', 'LL.M.'] \n",
    "            \n",
    "            #text_normalization loop\n",
    "                        \n",
    "            for word in list(account_name):\n",
    "                if word in badwords:\n",
    "                    account_name.remove(word)\n",
    "            account_name = \" \".join(account_name)\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            #In case there was an issue with the request call or the parameter parsed in the function we move to the next iteration\n",
    "             pass\n",
    "        \n",
    "        \n",
    "        # Search for the position of the user \n",
    "        \n",
    "        try:\n",
    "            position = clean_data(employee[\"primarySubtitle\"][\"text\"])\n",
    "            \n",
    "        except:\n",
    "            #In case we cannot retrieve the position we assign a nonAvailable value\n",
    "            position = \"N/A\"\n",
    "\n",
    "        # Search for the location\n",
    "        try: \n",
    "            location = employee[\"secondarySubtitle\"][\"text\"]\n",
    "        except:\n",
    "            #In case we cannot retrieve the location we assign a nonAvailable value\n",
    "            location = \"N/A\"\n",
    "\n",
    "        # Search for the profileLink. The profile link is what we are going to use in order to search and retrieve the further information for each of the users and their contacts.\n",
    "        try:\n",
    "            profile_link = employee[\"navigationUrl\"].split(\"?\")[0]\n",
    "            profile_link = unquote(profile_link)\n",
    "        except:\n",
    "            #In case we cannot retrieve the profile_link we assign a nonAvailable value\n",
    "            profile_link = \"N/A\"\n",
    "\n",
    "        \n",
    "        # Search the connection_degree\n",
    "        try:\n",
    "            degree_str = employee[\"entityCustomTrackingInfo\"][\"memberDistance\"]\n",
    "            degree = int(degree_str.split(\"DISTANCE_\")[-1])\n",
    "        except:\n",
    "            #when the iteration is about the user_target then the degree is 0\n",
    "            degree = 0\n",
    "            \n",
    "        \n",
    "        # Search the uniqueID. Each user has a unique ID in linkedIn backend system. We capture and save the id to use it as a primary key and for further https requests\n",
    "     \n",
    "        try:\n",
    "            \n",
    "            contact_id_urn = employee['image']['attributes'][0]['detailData']['nonEntityProfilePicture']['profile']['entityUrn'].split(\":\")[-1]\n",
    "        \n",
    "        except: \n",
    "            #In case we cannot retrieve the uniqueID we assign a nonAvailable value\n",
    "            contact_id_urn = \"N/A\"\n",
    "            \n",
    "        \n",
    "        # Search the userCode, which is the last part of the url and that we are going to use in order to parse it in our functions.\n",
    "        # Name of the LinkedIn account. \n",
    "        # e.x: https://www.linkedin.com/in/XXXX/ >> employee_information(XXXX)\n",
    "        \n",
    "        try:\n",
    "            contact_userCode = employee[\"navigationUrl\"].split(\"?\")[0].split(\"/\")[-1]\n",
    "            contact_userCode = unquote(contact_userCode)\n",
    "            \n",
    "        except:\n",
    "            #In case we cannot retrieve the userCode we assign a nonAvailable value\n",
    "            contact_userCode = \"N/A\" \n",
    "            \n",
    "            \n",
    "        ## return a dictionary with all the user's information\n",
    "        return {\"userID\": contact_id_urn,\"userCode\": contact_userCode,\"Nombre\":account_name, \"Puesto\": position, \"Grado\":degree, \"Ubicacion\":location, \"Link\":profile_link}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21737811",
   "metadata": {},
   "source": [
    "## Information from the contacts of the target_user\n",
    "    WE search and extract a list with the information for each of the contacts of our target_contact.\n",
    "    In order to do so we need 2 cookies from our navigator, li_at and JSESSIONID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "462cbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# li_at <- Cookie information about the active session\n",
    "# JSESSIONID <- Cookie information about the active session\n",
    "# target_user <- Name of the LinkedIn account. \n",
    "# e.x: https://www.linkedin.com/in/XXXX/ >> employee_information(XXXX)\n",
    "\n",
    "def contacts(user, li_at, JSESSIONID):\n",
    "    \n",
    "    headers = {\n",
    "        # Set the 'User-Agent' to simulate a request coming from a specific browser (in this case, Edge on Windows 10).\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/122.0.0.0', \n",
    "        # Specify the content type of the request body as JSON.\n",
    "        'Content-type': 'application/json', \n",
    "        # Include a CSRF token for security purposes, typically used to prevent cross-site request forgery attacks.\n",
    "        'Csrf-Token': JSESSIONID,\n",
    "        # Set cache control to avoid storing the response and revalidate each request.\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        # Maintain a persistent connection for multiple requests, reducing the overhead of re-establishing connections.\n",
    "        'Connection': 'keep-alive'\n",
    "    }\n",
    "    # Create a dictionary to store cookies, where 'li_at' and 'JSESSIONID' are keys and their corresponding values are variables.\n",
    "    cookies_dict = {\"li_at\": li_at, \"JSESSIONID\": JSESSIONID}\n",
    "    # URL-encode the 'user' variable to ensure it's safe to include in a URL or HTTP request.\n",
    "    cod_user = quote(user)\n",
    "    \n",
    "    \n",
    "    # Get the information of the target\n",
    "    # Construct the URL for the LinkedIn GraphQL API request, including the URL-encoded user variable (vanity name) as part of the query parameters.\n",
    "    url = f\"https://www.linkedin.com/voyager/api/graphql?variables=(vanityName:{cod_user})&queryId=voyagerIdentityDashProfiles.d8946426aeb23ab919d181f179a67a4d\"\n",
    "    # Send a GET request to the constructed URL with the specified headers and cookies for authentication and session management.\n",
    "    response = requests.get(url, headers=headers, cookies=cookies_dict)\n",
    "    # Parse the JSON response from the server and store it in the variable 'r'.\n",
    "    r = response.json()\n",
    "    \n",
    "    \n",
    "    # Information of the target\n",
    "    # Extract the first element of the 'identityDashProfilesByMemberIdentity' list, which contains the target user's profile information.\n",
    "    user_info = r['data']['identityDashProfilesByMemberIdentity']['elements'][0]\n",
    "    # Extract the user's unique ID (URN) by splitting the 'entityUrn' string and taking the last part.\n",
    "    id_urn = user_info['entityUrn'].split(\":\")[-1]\n",
    "    # Concatenate the user's first and last names to form their full name.\n",
    "    name = user_info['firstName'] + \" \" + user_info['lastName']\n",
    "    # Extract the user's current position or headline (usually their job title).\n",
    "    position = user_info['headline']\n",
    "    # Extract the user's location, using the default localized name from the geoLocation data.\n",
    "    location = user_info['geoLocation']['geo']['defaultLocalizedName']\n",
    "    \n",
    "    #create a df with the information and initialize a list for the contacts\n",
    "    user_info = pd.DataFrame({\"userID\": [id_urn],\"userCode\": [cod_user],\"Nombre\": [name], \"Puesto\": [position], \"Grado\": [0], \"Ubicacion\": [location], \"Link\": [\"https://www.linkedin.com/in/\" + user]})\n",
    "    list_contacts = []\n",
    "    \n",
    "          \n",
    "    # get all the contacts iterating witha step of 3 that is the max return of the call and append the information in the list \n",
    "    \n",
    "    for i in range(0,500,3):\n",
    "        # Construct the URL for the LinkedIn GraphQL API request, including pagination (start index) and search query parameters.\n",
    "        # The query is set to search for people who are connections of the user identified by 'id_urn'.\n",
    "   \n",
    "        url = f\"https://www.linkedin.com/voyager/api/graphql?variables=(start:{i},origin:MEMBER_PROFILE_CANNED_SEARCH,query:(flagshipSearchIntent:SEARCH_SRP,queryParameters:List((key:connectionOf,value:List({id_urn})),(key:network,value:List(F,S,O)),(key:resultType,value:List(PEOPLE))),includeFiltersInResponse:false))&queryId=voyagerSearchDashClusters.cc5c3924cc0402d1d8838b15bc96aa0b\"\n",
    "        \n",
    "        # Send a GET request to the constructed URL with the specified headers and cookies for authentication and session management.\n",
    "        response = requests.get(url, headers=headers, cookies=cookies_dict)\n",
    "        r = response.json()\n",
    "        \n",
    "        # appending the information of each of the contacts\n",
    "        try:\n",
    "            # Extract the list of users (contacts) from the response. This data is nested within 'searchDashClustersByAll'.\n",
    "            list_users = r['data']['searchDashClustersByAll']['elements'][0]['items']\n",
    "            \n",
    "            # Iterate over each user in the list and extract their information using the 'employee_information' function,\n",
    "            # then append the result to the 'list_contacts' list.\n",
    "            for user in list_users:\n",
    "                list_contacts.append(employee_information(user[\"item\"]['entityResult']))\n",
    "                \n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "    \n",
    "    \n",
    "    #Merge the information of the target and his contacts into a unique dataframe the targets information will be the first row with a zero degree connection with himself\n",
    "    contacts = pd.DataFrame(list_contacts)\n",
    "    contacts = contacts.drop_duplicates()\n",
    "    contacts = contacts[contacts['Nombre'] != \"LinkedIn Member\"]\n",
    "    contacts = pd.concat([user_info, contacts], ignore_index=True)\n",
    "    \n",
    "    return contacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
